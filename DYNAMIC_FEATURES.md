# ü§ñ Sistema Din√°mico de AURA

## ‚ú® Nueva Funcionalidad: Preguntas Generadas por LLM

El sistema AURA ahora usa **inteligencia artificial para generar preguntas din√°micamente** en lugar de usar preguntas predefinidas.

## üîÑ Diferencias entre Sistema Original vs Din√°mico

### ‚ùå Sistema Original (Predefinido)
```
AURA: ¬øCu√°l es tu presupuesto aproximado para esta compra?
Usuario: 1000 d√≥lares

AURA: ¬øQu√© tipo de producto est√°s buscando? (categor√≠a)
Usuario: Una laptop

AURA: ¬øQu√© caracter√≠sticas son m√°s importantes para ti?
Usuario: RAM y procesador

AURA: ¬øTienes alguna marca o especificaci√≥n preferida?
Usuario: Dell

AURA: ¬øPara qu√© uso principal necesitas este producto?
```

**Problemas:**
- ‚ùå Preguntas fijas, no se adaptan
- ‚ùå Siempre hace las mismas 5 preguntas
- ‚ùå No considera el contexto de respuestas anteriores
- ‚ùå Puede hacer preguntas redundantes

### ‚úÖ Sistema Din√°mico (Con LLM)

```
AURA: üëã ¬°Hola! Soy AURA, tu asistente inteligente de recomendaciones.
      ¬øQu√© tipo de producto est√°s buscando hoy?

Usuario: Necesito algo para trabajar desde casa

AURA: Entiendo que necesitas algo para trabajar desde casa. 
      ¬øPodr√≠as ser m√°s espec√≠fico? ¬øBuscas una computadora, 
      un escritorio, una silla ergon√≥mica, o algo m√°s?

Usuario: Una computadora port√°til

AURA: Perfecto, una laptop para trabajo remoto. 
      ¬øCu√°l es tu presupuesto aproximado?

Usuario: Hasta 1500 d√≥lares

AURA: Excelente. ¬øQu√© tipo de trabajo realizas? Por ejemplo, 
      ¬øprogramaci√≥n, dise√±o gr√°fico, videollamadas, o uso general?

Usuario: Principalmente programaci√≥n con Docker y VMs

AURA: Entiendo, necesitas bastante potencia. ¬øViajas frecuentemente 
      o la usar√°s principalmente en un lugar fijo? Esto me ayuda 
      a evaluar la importancia del peso y la bater√≠a.

Usuario: Viajo ocasionalmente

AURA: [Analiza que ya tiene suficiente informaci√≥n y procede]
      ‚ú® ¬°Perfecto! He analizado toda nuestra conversaci√≥n...
```

**Ventajas:**
- ‚úÖ Preguntas adaptadas al contexto
- ‚úÖ Conversaci√≥n natural y fluida
- ‚úÖ Detecta autom√°ticamente cu√°ndo tiene suficiente informaci√≥n
- ‚úÖ No hace preguntas redundantes
- ‚úÖ Puede pedir aclaraciones cuando algo no est√° claro
- ‚úÖ Se adapta al estilo de respuesta del usuario

## üß† C√≥mo Funciona Internamente

### Flujo del Sistema Din√°mico

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  1. INICIO DE CONVERSACI√ìN                              ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ  DynamicInformationCollectorAgent                       ‚îÇ
‚îÇ  - Genera primera pregunta con LLM                      ‚îÇ
‚îÇ  - Considera: contexto vac√≠o, objetivo general          ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                 ‚îÇ
                 ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  2. USUARIO RESPONDE                                    ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ  - Respuesta se a√±ade al historial                      ‚îÇ
‚îÇ  - LLM extrae informaci√≥n estructurada                  ‚îÇ
‚îÇ  - Actualiza: presupuesto, categor√≠a, caracter√≠sticas   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                 ‚îÇ
                 ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  3. GENERACI√ìN DE SIGUIENTE PREGUNTA                    ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ  LLM analiza:                                           ‚îÇ
‚îÇ  ‚úì Informaci√≥n ya recopilada                            ‚îÇ
‚îÇ  ‚úì Historial de conversaci√≥n                            ‚îÇ
‚îÇ  ‚úì Qu√© informaci√≥n falta                                ‚îÇ
‚îÇ  ‚úì Contexto de la √∫ltima respuesta                      ‚îÇ
‚îÇ                                                          ‚îÇ
‚îÇ  Genera pregunta espec√≠fica y contextual                ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                 ‚îÇ
                 ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  4. EVALUACI√ìN DE SUFICIENCIA                           ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ  ¬øTenemos suficiente informaci√≥n?                       ‚îÇ
‚îÇ  - Presupuesto: ‚úì                                       ‚îÇ
‚îÇ  - Categor√≠a: ‚úì                                         ‚îÇ
‚îÇ  - Uso principal: ‚úì                                     ‚îÇ
‚îÇ  - Caracter√≠sticas clave: ‚úì                             ‚îÇ
‚îÇ                                                          ‚îÇ
‚îÇ  SI ‚Üí Proceder a recomendaciones                        ‚îÇ
‚îÇ  NO ‚Üí Repetir desde paso 2                              ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### Informaci√≥n que Rastrea

```python
information_gathered = {
    'presupuesto': "1200-1500 d√≥lares",
    'categoria': "Laptop",
    'caracteristicas': ["16GB RAM", "Procesador potente", "Port√°til"],
    'uso_principal': "Programaci√≥n con Docker y VMs",
    'preferencias_marca': "Dell preferido, abierto a otras",
    'prioridades': ["Rendimiento", "Portabilidad"],
    'restricciones': ["Viaja ocasionalmente"]
}
```

## üìä Comparaci√≥n de Resultados

### Ejemplo 1: Usuario Claro

**Sistema Predefinido:**
- 5 preguntas fijas
- 5 respuestas del usuario
- Total: 10 intercambios

**Sistema Din√°mico:**
- 3-4 preguntas adaptadas
- Detecta informaci√≥n completa antes
- Total: 6-8 intercambios ‚úÖ M√°s eficiente

### Ejemplo 2: Usuario Vago

**Sistema Predefinido:**
```
AURA: ¬øCu√°l es tu presupuesto?
Usuario: No s√©, algo normal
AURA: ¬øQu√© tipo de producto buscas?
Usuario: Algo para la casa
[Contin√∫a sin aclarar]
```

**Sistema Din√°mico:**
```
AURA: ¬øCu√°l es tu presupuesto?
Usuario: No s√©, algo normal
AURA: Entiendo. ¬øPodr√≠as darme un rango aproximado? 
      Por ejemplo, ¬ømenos de $500, entre $500-$1000, 
      o m√°s de $1000?
Usuario: Entre 500 y 1000
[El LLM pide aclaraciones cuando es necesario] ‚úÖ
```

## üéØ Ventajas Clave

### 1. Adaptabilidad
```python
# Si el usuario menciona m√∫ltiples cosas en una respuesta
Usuario: "Necesito una laptop de 1200 d√≥lares para programar"

# Sistema din√°mico extrae:
- Categor√≠a: Laptop ‚úì
- Presupuesto: 1200 d√≥lares ‚úì
- Uso: Programaci√≥n ‚úì

# Siguiente pregunta se adapta:
AURA: "¬øQu√© lenguajes de programaci√≥n usas principalmente 
       y necesitas ejecutar entornos virtuales o contenedores?"
```

### 2. Detecci√≥n de Informaci√≥n Suficiente
```python
def is_information_sufficient():
    # Verifica campos cr√≠ticos
    has_budget = information_gathered['presupuesto'] is not None
    has_category = information_gathered['categoria'] is not None
    has_use = information_gathered['uso_principal'] is not None
    
    # O m√°ximo de preguntas alcanzado
    return (has_budget and has_category) or questions_asked >= 7
```

### 3. Contexto Conversacional
```python
# El LLM recibe en cada pregunta:
prompt = f"""
INFORMACI√ìN YA RECOPILADA:
{information_gathered}

CONVERSACI√ìN HASTA AHORA:
{conversation_history}

√öLTIMA RESPUESTA DEL USUARIO:
{user_response}

Genera la siguiente pregunta m√°s relevante...
"""
```

## üöÄ C√≥mo Usar el Sistema Din√°mico

### Opci√≥n 1: Usar main.py (Ya Configurado)
```bash
uv run python main.py
```

El sistema ahora usa autom√°ticamente el agente din√°mico.

### Opci√≥n 2: Usar Program√°ticamente
```python
from src.rag.vector_store import VectorStore
from src.orchestrator_dynamic import DynamicMultiAgentOrchestrator

# Cargar vectorstore
vector_store = VectorStore()
vector_store.load_vectorstore()

# Crear orquestador din√°mico
orchestrator = DynamicMultiAgentOrchestrator(vector_store)

# Iniciar sesi√≥n
greeting = orchestrator.start_session()
print(greeting)

# Procesar respuestas
response = orchestrator.process_user_input("Busco una laptop")
print(response['message'])
```

## ‚öôÔ∏è Configuraci√≥n

### Ajustar N√∫mero M√°ximo de Preguntas

```python
# En src/agents/dynamic_collector.py
self.max_questions = 7  # Cambiar este valor
```

### Modificar Criterios de Suficiencia

```python
# En src/agents/dynamic_collector.py
def is_information_sufficient(self):
    # Personalizar l√≥gica
    critical_fields = ['categoria', 'presupuesto', 'uso_principal']
    has_critical = all(self.information_gathered.get(field) 
                      for field in critical_fields)
    return has_critical
```

## üìù Notas Importantes

### L√≠mites de API
El sistema din√°mico hace **m√°s llamadas al LLM**:
- 1 llamada por cada pregunta generada
- 1 llamada para extraer informaci√≥n
- 1 llamada para an√°lisis final

**Soluci√≥n**: El sistema tiene reintentos autom√°ticos y maneja los l√≠mites de cuota.

### Latencia
- Primera pregunta: ~2-3 segundos
- Preguntas subsecuentes: ~2-3 segundos cada una
- M√°s lento que preguntas predefinidas, pero **mucho m√°s inteligente**

### Calidad de Conversaci√≥n
Depende del modelo LLM usado:
- `gemini-1.5-flash`: R√°pido, buena calidad ‚úÖ
- `gemini-1.5-pro`: M√°s lento, excelente calidad ‚≠ê
- `gemini-2.5-flash`: Balance √≥ptimo (actual) ‚ö°

## üéì Ejemplos de Conversaciones Reales

### Conversaci√≥n 1: Usuario Experimentado
```
AURA: ¬øQu√© producto est√°s buscando?
Usuario: MacBook Pro M3 o similar, presupuesto 2500

AURA: Entiendo, buscas laptops de alto rendimiento. 
      ¬øPara qu√© uso espec√≠fico? ¬øDesarrollo, dise√±o, video?
Usuario: Desarrollo iOS y machine learning

AURA: Perfecto. ¬øNecesitas GPU dedicada o la GPU integrada 
      del M3 es suficiente para tus modelos de ML?
[Solo 3 preguntas, muy espec√≠ficas] ‚úÖ
```

### Conversaci√≥n 2: Usuario Novato
```
AURA: ¬øQu√© producto est√°s buscando?
Usuario: No s√©, algo para estudiar

AURA: Entiendo. ¬øEstudias en l√≠nea o presencial? 
      ¬øNecesitas algo port√°til o para usar en casa?
Usuario: En l√≠nea, desde mi cuarto

AURA: Perfecto. ¬øQu√© programas o aplicaciones usas 
      principalmente? ¬øNavegador, Office, algo m√°s?
[Gu√≠a al usuario paso a paso] ‚úÖ
```

## üîß Troubleshooting

### "Muchas preguntas"
Reduce `max_questions` en `dynamic_collector.py`

### "Preguntas no relevantes"
Mejora el prompt del sistema en `generate_next_question()`

### "Error de cuota"
Espera unos minutos o cambia a un modelo con mayor cuota

## üìö Archivos Relacionados

- `src/agents/dynamic_collector.py` - Agente din√°mico
- `src/orchestrator_dynamic.py` - Orquestador din√°mico
- `main.py` - Usa sistema din√°mico por defecto
- `test_dynamic.py` - Pruebas del sistema

---

**¬°El sistema din√°mico est√° activo! Ejecuta `python main.py` para probarlo.** üöÄ

