"""
Agente preguntador interactivo para recopilar informaci√≥n del usuario
Utiliza Gemini (Google LLM) para generar preguntas contextuales e inteligentes
"""
from typing import Dict, Any, List, Optional
from langchain_core.prompts import ChatPromptTemplate
from pydantic import BaseModel, Field
import json

from src.agents.base_agent import BaseAgent


class ExtractedInfo(BaseModel):
    """Informaci√≥n extra√≠da de las respuestas del usuario"""
    categoria_producto: Optional[str] = Field(default=None, description="Tipo de producto buscado")
    presupuesto_min: Optional[float] = Field(default=None, description="Presupuesto m√≠nimo")
    presupuesto_max: Optional[float] = Field(default=None, description="Presupuesto m√°ximo")
    sin_limite_presupuesto: bool = Field(default=False, description="Si el usuario no tiene l√≠mite de presupuesto")
    uso_principal: Optional[str] = Field(default=None, description="Uso principal del producto")
    caracteristicas_clave: List[str] = Field(default_factory=list, description="Caracter√≠sticas importantes")
    preferencias_marca: List[str] = Field(default_factory=list, description="Marcas preferidas")
    restricciones: List[str] = Field(default_factory=list, description="Limitaciones o restricciones")
    nivel_urgencia: Optional[str] = Field(default=None, description="Qu√© tan urgente es la compra")
    contexto_adicional: Optional[str] = Field(default=None, description="Informaci√≥n adicional relevante")


class ConversationContext(BaseModel):
    """Contexto enriquecido de la conversaci√≥n"""
    questions_asked: List[str] = Field(default_factory=list, description="Preguntas ya realizadas")
    user_answers: List[str] = Field(default_factory=list, description="Respuestas del usuario")
    topics_covered: List[str] = Field(default_factory=list, description="Temas ya cubiertos")
    current_question_number: int = Field(default=0, description="N√∫mero de pregunta actual")
    extracted_info: ExtractedInfo = Field(default_factory=ExtractedInfo, description="Informaci√≥n extra√≠da")
    information_score: Dict[str, float] = Field(default_factory=dict, description="Score de informaci√≥n recopilada")


class QuestionerAgent(BaseAgent):
    """
    Agente inteligente que hace preguntas din√°micas al usuario
    para recopilar informaci√≥n sobre sus necesidades.
    
    Caracter√≠sticas:
    - M√°ximo 5 preguntas
    - Preguntas adaptativas basadas en respuestas previas
    - Conversaci√≥n natural y contextual
    - Extracci√≥n inteligente de informaci√≥n
    """
    
    MAX_QUESTIONS = 5
    
    def __init__(self):
        super().__init__(
            name="Agente Preguntador Interactivo",
            role="Recopilar informaci√≥n mediante preguntas inteligentes y adaptativas"
        )
        
        self.conversation_context = ConversationContext()
        
        # Prompt para extracci√≥n inteligente de informaci√≥n usando Gemini
        self.extraction_prompt = ChatPromptTemplate.from_messages([
            ("system", """Eres un experto analizador de conversaciones de ventas. Tu tarea es extraer 
            informaci√≥n estructurada de las respuestas del usuario.
            
            üìã INFORMACI√ìN A EXTRAER:
            1. **categoria_producto**: Tipo de producto (laptop, tel√©fono, tablet, etc.) - STRING o null
            2. **presupuesto_min**: Presupuesto m√≠nimo en n√∫meros - FLOAT o null
            3. **presupuesto_max**: Presupuesto m√°ximo en n√∫meros - FLOAT o null
            4. **sin_limite_presupuesto**: Si el usuario indica que NO tiene l√≠mite de presupuesto - BOOLEAN (true/false)
               - ‚ö†Ô∏è CR√çTICO: SIEMPRE debes evaluar este campo. Si no hay informaci√≥n, usa false.
               - Detecta frases como: "no tengo l√≠mite", "sin l√≠mite de presupuesto", "presupuesto ilimitado", 
                 "no hay l√≠mite", "dinero no es problema", "presupuesto flexible", "no tengo l√≠mite de presupuesto",
                 "presupuesto no es problema", "cualquier precio", "sin restricci√≥n de precio", etc.
               - Si el usuario dice expl√≠citamente que NO tiene l√≠mite ‚Üí true
               - Si el usuario menciona un presupuesto espec√≠fico ‚Üí false
               - Si no hay informaci√≥n sobre presupuesto ‚Üí false
               - Si es true, entonces presupuesto_min y presupuesto_max deben ser null
            5. **uso_principal**: Uso principal del producto - STRING o null
            6. **caracteristicas_clave**: Lista de caracter√≠sticas importantes - LIST[STRING]
            7. **preferencias_marca**: Marcas mencionadas o preferidas - LIST[STRING]
            8. **restricciones**: Limitaciones o restricciones - LIST[STRING]
            9. **nivel_urgencia**: ¬øQu√© tan urgente? (inmediato/pronto/sin_prisa) - STRING o null
            10. **contexto_adicional**: Cualquier otra informaci√≥n relevante - STRING o null
            
            üéØ INSTRUCCIONES:
            - Extrae SOLO informaci√≥n EXPL√çCITA o CLARAMENTE IMPL√çCITA
            - Si no hay informaci√≥n sobre un campo, usa null o lista vac√≠a []
            - Para presupuestos, convierte texto a n√∫meros (ej: "mil euros" ‚Üí 1000.0)
            - ‚ö†Ô∏è IMPORTANTE: El campo "sin_limite_presupuesto" SIEMPRE debe estar presente en el JSON (true o false)
            - Si el usuario menciona "no tengo l√≠mite" o similar ‚Üí sin_limite_presupuesto: true
            - Si el usuario menciona un presupuesto espec√≠fico ‚Üí sin_limite_presupuesto: false
            - Si no hay informaci√≥n sobre presupuesto ‚Üí sin_limite_presupuesto: false
            - S√© conservador: mejor null que informaci√≥n incorrecta
            
            üìù INFORMACI√ìN YA RECOPILADA:
            {previous_info}
            
            üí¨ √öLTIMA RESPUESTA DEL USUARIO:
            "{user_response}"
            
            üéØ RESPONDE EN FORMATO JSON V√ÅLIDO (sin markdown, sin comentarios):
            ‚ö†Ô∏è IMPORTANTE: Todos los campos deben estar presentes en el JSON, incluso si son null o false.
            {{
                "categoria_producto": "valor o null",
                "presupuesto_min": n√∫mero o null,
                "presupuesto_max": n√∫mero o null,
                "sin_limite_presupuesto": true o false,  // ‚ö†Ô∏è SIEMPRE incluir este campo (true si no hay l√≠mite, false en caso contrario)
                "uso_principal": "valor o null",
                "caracteristicas_clave": ["lista", "de", "caracter√≠sticas"],
                "preferencias_marca": ["lista", "de", "marcas"],
                "restricciones": ["lista", "de", "restricciones"],
                "nivel_urgencia": "valor o null",
                "contexto_adicional": "valor o null"
            }}"""),
            ("user", "Extrae la informaci√≥n de esta respuesta:")
        ])
        
        # Prompt mejorado para generar preguntas ultra-personalizadas con Gemini
        self.question_prompt = ChatPromptTemplate.from_messages([
            ("system", """Eres un asistente de compras experto y emp√°tico que hace preguntas INTELIGENTES 
            y PERSONALIZADAS para entender las necesidades del usuario. Tu objetivo es descubrir qu√© 
            producto necesita realmente y por qu√©.
            
            üéØ ESTRATEGIA AVANZADA DE PREGUNTAS:
            
            1. **ANALIZA LA INFORMACI√ìN EXTRA√çDA**: Revisa qu√© datos ya tienes
            2. **IDENTIFICA VAC√çOS CR√çTICOS**: ¬øQu√© informaci√≥n esencial falta?
            3. **PRIORIZA INTELIGENTEMENTE**: Pregunta primero lo m√°s importante
            4. **CONECTA Y PROFUNDIZA**: Usa lo que sabes para preguntas m√°s espec√≠ficas
            5. **S√â NATURAL**: Haz que la conversaci√≥n fluya org√°nicamente
            
            üìä INFORMACI√ìN YA RECOPILADA:
            {extracted_info_summary}
            
            üéØ INFORMACI√ìN QUE A√öN FALTA:
            {missing_info}
            
            üìù CONVERSACI√ìN COMPLETA:
            {conversation_history}
            
            üí° EJEMPLOS DE PREGUNTAS CONTEXTUALES:
            
            Escenario 1 - Ya sabes: laptop para programaci√≥n
            Pregunta inteligente: "Genial, para programaci√≥n. ¬øTrabajas con herramientas pesadas como Docker, 
            m√°quinas virtuales o IDEs como Android Studio? Esto nos ayudar√° a definir cu√°nta RAM necesitas."
            
            Escenario 2 - Ya sabes: tel√©fono, presupuesto 500-700‚Ç¨
            Pregunta inteligente: "Perfecto, con ese presupuesto tienes buenas opciones. ¬øQu√© es m√°s importante 
            para ti: la calidad de la c√°mara, la duraci√≥n de bater√≠a, o el rendimiento para juegos?"
            
            Escenario 3 - Ya sabes: tablet, para estudiar y ver series
            Pregunta inteligente: "Entiendo, para estudiar y entretenimiento. ¬øPrefieres algo ligero y port√°til 
            como una tablet de 10 pulgadas, o una pantalla m√°s grande tipo 12 pulgadas aunque pese un poco m√°s?"
            
            ‚ö†Ô∏è REGLAS CR√çTICAS:
            1. **NO repitas informaci√≥n** que el usuario ya dio
            2. **NO preguntes** sobre campos que ya tienes completos
            3. **USA lo que sabes** para hacer preguntas m√°s espec√≠ficas
            4. **UNA pregunta a la vez**, clara y directa
            5. **S√â conversacional**, no rob√≥tico
            
            üéØ GENERA UNA PREGUNTA que:
            - Est√© basada en el contexto completo
            - Busque la informaci√≥n m√°s cr√≠tica que falta
            - Sea natural y emp√°tica
            - Ayude a entender mejor las necesidades del usuario
            
            Responde SOLO con la pregunta, sin explicaciones adicionales."""),
            ("user", "Genera la siguiente pregunta contextual:")
        ])
        
        # Prompt mejorado para analizar si necesitamos m√°s informaci√≥n
        self.analysis_prompt = ChatPromptTemplate.from_messages([
            ("system", """Eres un analista experto en comprensi√≥n de necesidades de clientes.
            
            üéØ TU TAREA: Determinar si tenemos SUFICIENTE informaci√≥n para recomendar productos.
            
            üìä INFORMACI√ìN EXTRA√çDA HASTA AHORA:
            {extracted_info_summary}
            
            üìã CRITERIOS DE EVALUACI√ìN:
            
            **INFORMACI√ìN CR√çTICA** (debe estar presente):
            - ‚úì Categor√≠a de producto (qu√© busca)
            - ‚úì Presupuesto aproximado (rango de precio) O indicaci√≥n de sin l√≠mite de presupuesto
            - ‚úì Uso principal O caracter√≠sticas clave
            
            **INFORMACI√ìN √öTIL** (deseable pero no esencial):
            - Preferencias de marca
            - Restricciones espec√≠ficas
            - Urgencia de compra
            - Contexto adicional
            
            ‚úÖ TENEMOS SUFICIENTE SI:
            - Categor√≠a + (Presupuesto O Sin l√≠mite de presupuesto) + (Uso O Caracter√≠sticas) est√°n presentes
            - La informaci√≥n es lo suficientemente espec√≠fica para recomendar
            - Tenemos al menos 2 de los 3 elementos cr√≠ticos con buen detalle
            
            ‚ö†Ô∏è NECESITAMOS M√ÅS SI:
            - Falta categor√≠a de producto (cr√≠tico)
            - No sabemos el presupuesto ni aproximado ni si no hay l√≠mite (cr√≠tico)
            - No tenemos idea del uso ni caracter√≠sticas deseadas
            - La informaci√≥n es muy vaga o ambigua
            
            üéØ AN√ÅLISIS ACTUAL:
            Preguntas realizadas: {questions_count}/{max_questions}
            Score de informaci√≥n: {information_score}%
            
            üìù CONVERSACI√ìN:
            {conversation_history}
            
            üéØ DECISI√ìN:
            Responde SOLO con una palabra seguida de breve explicaci√≥n:
            - "CONTINUAR: [raz√≥n]" - Si falta informaci√≥n cr√≠tica
            - "SUFICIENTE: [raz√≥n]" - Si podemos hacer buenas recomendaciones
            
            S√© eficiente: mejor suficiente informaci√≥n que perfecta."""),
            ("user", "¬øDebemos continuar preguntando o ya tenemos suficiente?")
        ])
        
        # Prompt para generar la primera pregunta (tambi√©n personalizada)
        self.initial_question_prompt = ChatPromptTemplate.from_messages([
            ("system", """Eres un asistente de compras amigable y profesional.
            
            üéØ TAREA: Genera una pregunta de APERTURA c√°lida y efectiva para iniciar la conversaci√≥n.
            
            ‚úÖ LA PREGUNTA DEBE:
            1. Ser amigable y acogedora
            2. Preguntar qu√© tipo de producto busca
            3. Ser abierta pero enfocada
            4. Incluir un saludo breve
            5. Mostrar entusiasmo por ayudar
            
            üí° EJEMPLOS DE BUENAS PREGUNTAS INICIALES:
            - "¬°Hola! üëã Estoy aqu√≠ para ayudarte a encontrar el producto perfecto. ¬øQu√© est√°s buscando hoy?"
            - "¬°Bienvenido! üòä Me encantar√≠a ayudarte. ¬øQu√© tipo de producto tienes en mente?"
            - "¬°Hola! Soy tu asistente de compras. ¬øEn qu√© producto est√°s interesado hoy?"
            
            ‚ö†Ô∏è EVITA:
            - Ser demasiado formal o rob√≥tico
            - Hacer m√∫ltiples preguntas a la vez
            - Ser muy largo o explicativo
            
            Genera SOLO la pregunta, sin texto adicional."""),
            ("user", "Genera la pregunta de apertura:")
        ])
    
    def generate_next_question(self) -> Optional[str]:
        """
        Genera la siguiente pregunta basada en el contexto de la conversaci√≥n usando Gemini
        
        Returns:
            Siguiente pregunta o None si no hay m√°s preguntas
        """
        if self.conversation_context.current_question_number >= self.MAX_QUESTIONS:
            return None
        
        # Si es la primera pregunta, usar prompt especial de apertura
        if self.conversation_context.current_question_number == 0:
            try:
                chain = self.initial_question_prompt | self.llm
                result = self._invoke_with_rate_limit(chain, {})
                question = result.content.strip()
                
                self.conversation_context.current_question_number += 1
                self.conversation_context.questions_asked.append(question)
                return question
            except Exception as e:
                print(f"Error generando pregunta inicial: {e}")
                # Fallback a pregunta por defecto si falla
                question = "¬°Hola! üëã ¬øQu√© tipo de producto est√°s buscando hoy?"
                self.conversation_context.current_question_number += 1
                self.conversation_context.questions_asked.append(question)
                return question
        
        # Verificar si necesitamos m√°s informaci√≥n (despu√©s de 3 preguntas)
        if self.conversation_context.current_question_number >= 3:
            should_continue = self._should_continue_asking()
            if not should_continue:
                return None
        
        # Generar contexto enriquecido para Gemini
        conversation_history = self._format_conversation_history()
        extracted_info_summary = self._format_extracted_info()
        missing_info = self._identify_missing_info()
        
        # Generar siguiente pregunta personalizada con Gemini usando contexto completo
        try:
            chain = self.question_prompt | self.llm
            result = self._invoke_with_rate_limit(chain, {
                "extracted_info_summary": extracted_info_summary,
                "missing_info": missing_info,
                "conversation_history": conversation_history
            })
            
            question = result.content.strip()
            
            # Limpiar la pregunta (remover comillas extras, markdown, etc.)
            question = question.strip('"').strip("'").strip('`')
            if question.startswith("Pregunta:"):
                question = question.replace("Pregunta:", "").strip()
            
            self.conversation_context.current_question_number += 1
            self.conversation_context.questions_asked.append(question)
            
            print(f"‚úÖ Pregunta {self.conversation_context.current_question_number} generada")
            
            return question
            
        except Exception as e:
            print(f"‚ö†Ô∏è  Error generando pregunta con Gemini: {e}")
            return None
    
    def add_user_response(self, response: str):
        """
        A√±ade una respuesta del usuario al contexto y extrae informaci√≥n clave usando Gemini
        
        Args:
            response: Respuesta del usuario
        """
        self.conversation_context.user_answers.append(response)
        
        # Extraer informaci√≥n estructurada usando Gemini
        self._extract_information_with_llm(response)
        
        # Extraer temas mencionados (m√©todo complementario r√°pido)
        self._extract_topics(response)
        
        # Calcular score de informaci√≥n recopilada
        self._calculate_information_score()
    
    def _should_continue_asking(self) -> bool:
        """
        Determina si debemos continuar haciendo preguntas usando an√°lisis inteligente con Gemini
        
        Returns:
            True si debemos continuar, False si tenemos suficiente informaci√≥n
        """
        if self.conversation_context.current_question_number >= self.MAX_QUESTIONS:
            return False
        
        # Obtener contexto enriquecido
        conversation_history = self._format_conversation_history()
        extracted_info_summary = self._format_extracted_info()
        info_score = self._calculate_information_score()
        
        try:
            chain = self.analysis_prompt | self.llm
            result = self._invoke_with_rate_limit(chain, {
                "conversation_history": conversation_history,
                "extracted_info_summary": extracted_info_summary,
                "information_score": info_score,
                "questions_count": self.conversation_context.current_question_number,
                "max_questions": self.MAX_QUESTIONS
            })
            
            analysis = result.content.strip()
            
            # Si el an√°lisis indica CONTINUAR, seguimos
            should_continue = "CONTINUAR" in analysis.upper()
            
            # Log del an√°lisis para debugging
            print(f"üìä An√°lisis LLM: {analysis[:100]}...")
            print(f"üéØ Decisi√≥n: {'Continuar' if should_continue else 'Suficiente informaci√≥n'}")
            
            return should_continue
            
        except Exception as e:
            print(f"‚ö†Ô∏è  Error analizando contexto: {e}")
            # En caso de error, continuamos solo si el score es bajo
            return info_score < 60
    
    def _extract_topics(self, response: str):
        """
        Extrae temas mencionados en la respuesta para evitar preguntas redundantes
        
        Args:
            response: Respuesta del usuario
        """
        # Palabras clave para identificar temas
        topic_keywords = {
            "presupuesto": ["precio", "costo", "presupuesto", "dinero", "‚Ç¨", "$", "econ√≥mico", "barato", "caro"],
            "categor√≠a": ["laptop", "tel√©fono", "tablet", "auriculares", "teclado", "monitor", "televisor"],
            "uso": ["trabajo", "gaming", "estudio", "casa", "oficina", "port√°til", "uso", "utilizar"],
            "caracter√≠sticas": ["pantalla", "memoria", "almacenamiento", "procesador", "bater√≠a", "c√°mara"],
            "marca": ["marca", "apple", "samsung", "sony", "lenovo", "hp", "dell", "asus"]
        }
        
        response_lower = response.lower()
        
        for topic, keywords in topic_keywords.items():
            if any(keyword in response_lower for keyword in keywords):
                if topic not in self.conversation_context.topics_covered:
                    self.conversation_context.topics_covered.append(topic)
    
    def _extract_information_with_llm(self, response: str):
        """
        Extrae informaci√≥n estructurada de la respuesta del usuario usando Gemini
        
        Args:
            response: Respuesta del usuario
        """
        try:
            # Formatear informaci√≥n previa
            previous_info = self._format_extracted_info()
            
            # Usar Gemini para extraer informaci√≥n estructurada
            chain = self.extraction_prompt | self.llm
            result = self._invoke_with_rate_limit(chain, {
                "user_response": response,
                "previous_info": previous_info
            })
            
            # Parsear respuesta JSON
            extracted_text = result.content.strip()
            
            # Limpiar markdown si est√° presente
            if "```json" in extracted_text:
                extracted_text = extracted_text.split("```json")[1].split("```")[0].strip()
            elif "```" in extracted_text:
                extracted_text = extracted_text.split("```")[1].split("```")[0].strip()
            
            extracted_data = json.loads(extracted_text)
            
            # Actualizar informaci√≥n extra√≠da (merge con info previa)
            info = self.conversation_context.extracted_info
            
            # Actualizar solo campos no nulos
            if extracted_data.get("categoria_producto"):
                info.categoria_producto = extracted_data["categoria_producto"]
            
            if extracted_data.get("presupuesto_min") is not None:
                info.presupuesto_min = float(extracted_data["presupuesto_min"])
                
            if extracted_data.get("presupuesto_max") is not None:
                info.presupuesto_max = float(extracted_data["presupuesto_max"])
            
            # Procesar sin_limite_presupuesto
            # IMPORTANTE: Siempre actualizar si el LLM detecta este campo (incluso si es false)
            # Esto asegura que se capture correctamente cuando el usuario dice "no tengo l√≠mite"
            if "sin_limite_presupuesto" in extracted_data:
                info.sin_limite_presupuesto = bool(extracted_data["sin_limite_presupuesto"])
                # Si el usuario dice que no tiene l√≠mite, asegurar que presupuesto_min/max sean None
                if info.sin_limite_presupuesto:
                    info.presupuesto_min = None
                    info.presupuesto_max = None
                
            if extracted_data.get("uso_principal"):
                info.uso_principal = extracted_data["uso_principal"]
            
            if extracted_data.get("nivel_urgencia"):
                info.nivel_urgencia = extracted_data["nivel_urgencia"]
            
            if extracted_data.get("contexto_adicional"):
                # Combinar con contexto previo si existe
                if info.contexto_adicional:
                    info.contexto_adicional += f" | {extracted_data['contexto_adicional']}"
                else:
                    info.contexto_adicional = extracted_data["contexto_adicional"]
            
            # Para listas, hacer merge (no duplicar)
            for caracteristica in extracted_data.get("caracteristicas_clave", []):
                if caracteristica and caracteristica not in info.caracteristicas_clave:
                    info.caracteristicas_clave.append(caracteristica)
            
            for marca in extracted_data.get("preferencias_marca", []):
                if marca and marca not in info.preferencias_marca:
                    info.preferencias_marca.append(marca)
            
            for restriccion in extracted_data.get("restricciones", []):
                if restriccion and restriccion not in info.restricciones:
                    info.restricciones.append(restriccion)
            
            print(f"‚úÖ Informaci√≥n extra√≠da: {len(extracted_data)} campos procesados")
            
        except json.JSONDecodeError as e:
            print(f"‚ö†Ô∏è  Error parseando JSON de extracci√≥n: {e}")
            print(f"Respuesta recibida: {extracted_text[:200]}")
        except Exception as e:
            print(f"‚ö†Ô∏è  Error extrayendo informaci√≥n con LLM: {e}")
    
    def _calculate_information_score(self) -> float:
        """
        Calcula un score (0-100) de cu√°nta informaci√≥n cr√≠tica hemos recopilado
        
        Returns:
            Score de 0 a 100
        """
        info = self.conversation_context.extracted_info
        score = 0.0
        
        # Informaci√≥n cr√≠tica (70% del score)
        if info.categoria_producto:
            score += 25
        
        # Presupuesto: puede ser espec√≠fico o sin l√≠mite
        # IMPORTANTE: Si sin_limite_presupuesto es True, tambi√©n cuenta como informaci√≥n de presupuesto
        if info.sin_limite_presupuesto or info.presupuesto_min or info.presupuesto_max:
            score += 25
        
        if info.uso_principal or len(info.caracteristicas_clave) > 0:
            score += 20
        
        # Informaci√≥n adicional √∫til (30% del score)
        if len(info.caracteristicas_clave) >= 2:
            score += 10
        
        if len(info.preferencias_marca) > 0:
            score += 5
        
        if len(info.restricciones) > 0:
            score += 5
        
        if info.nivel_urgencia:
            score += 5
        
        if info.contexto_adicional:
            score += 5
        
        self.conversation_context.information_score["total"] = score
        return score
    
    def _format_extracted_info(self) -> str:
        """
        Formatea la informaci√≥n extra√≠da en un texto legible
        
        Returns:
            String formateado con la informaci√≥n extra√≠da
        """
        info = self.conversation_context.extracted_info
        
        lines = []
        lines.append("üìã INFORMACI√ìN EXTRA√çDA:")
        lines.append("")
        
        lines.append(f"üè∑Ô∏è  Categor√≠a: {info.categoria_producto or '‚ùå No especificada'}")
        
        if info.sin_limite_presupuesto:
            lines.append("üí∞ Presupuesto: ‚úÖ Sin l√≠mite de presupuesto")
        elif info.presupuesto_min or info.presupuesto_max:
            presupuesto_str = ""
            if info.presupuesto_min and info.presupuesto_max:
                presupuesto_str = f"{info.presupuesto_min} - {info.presupuesto_max}‚Ç¨"
            elif info.presupuesto_min:
                presupuesto_str = f"Desde {info.presupuesto_min}‚Ç¨"
            elif info.presupuesto_max:
                presupuesto_str = f"Hasta {info.presupuesto_max}‚Ç¨"
            lines.append(f"üí∞ Presupuesto: {presupuesto_str}")
        else:
            lines.append("üí∞ Presupuesto: ‚ùå No especificado")
        
        lines.append(f"üéØ Uso principal: {info.uso_principal or '‚ùå No especificado'}")
        
        if info.caracteristicas_clave:
            lines.append(f"‚öôÔ∏è  Caracter√≠sticas: {', '.join(info.caracteristicas_clave)}")
        else:
            lines.append("‚öôÔ∏è  Caracter√≠sticas: ‚ùå No especificadas")
        
        if info.preferencias_marca:
            lines.append(f"üè¢ Marcas: {', '.join(info.preferencias_marca)}")
        
        if info.restricciones:
            lines.append(f"‚ö†Ô∏è  Restricciones: {', '.join(info.restricciones)}")
        
        if info.nivel_urgencia:
            lines.append(f"‚è∞ Urgencia: {info.nivel_urgencia}")
        
        if info.contexto_adicional:
            lines.append(f"üìù Contexto: {info.contexto_adicional[:100]}...")
        
        return "\n".join(lines)
    
    def _identify_missing_info(self) -> str:
        """
        Identifica qu√© informaci√≥n cr√≠tica a√∫n falta
        
        Returns:
            String describiendo la informaci√≥n faltante
        """
        info = self.conversation_context.extracted_info
        missing = []
        
        if not info.categoria_producto:
            missing.append("‚ùå Categor√≠a de producto (CR√çTICO)")
        
        # Si no hay l√≠mite de presupuesto, no falta informaci√≥n de presupuesto
        if not info.sin_limite_presupuesto and not info.presupuesto_min and not info.presupuesto_max:
            missing.append("‚ùå Presupuesto aproximado (CR√çTICO)")
        
        if not info.uso_principal and len(info.caracteristicas_clave) == 0:
            missing.append("‚ùå Uso principal o caracter√≠sticas clave (CR√çTICO)")
        
        if len(info.caracteristicas_clave) < 2:
            missing.append("‚ö†Ô∏è  Caracter√≠sticas espec√≠ficas (√öTIL)")
        
        if len(info.preferencias_marca) == 0:
            missing.append("‚ö†Ô∏è  Preferencias de marca (√öTIL)")
        
        if not missing:
            return "‚úÖ Tenemos toda la informaci√≥n esencial"
        
        return "\n".join(missing)
    
    def _format_conversation_history(self) -> str:
        """
        Formatea el historial de la conversaci√≥n para el contexto
        
        Returns:
            Historial formateado
        """
        if not self.conversation_context.questions_asked:
            return "Conversaci√≥n reci√©n iniciada."
        
        history = []
        for i, (question, answer) in enumerate(zip(
            self.conversation_context.questions_asked,
            self.conversation_context.user_answers
        ), 1):
            history.append(f"Pregunta {i}: {question}")
            history.append(f"Respuesta {i}: {answer}")
            history.append("")
        
        return "\n".join(history)
    
    def has_more_questions(self) -> bool:
        """
        Verifica si hay m√°s preguntas por hacer
        
        Returns:
            True si puede hacer m√°s preguntas
        """
        return self.conversation_context.current_question_number < self.MAX_QUESTIONS
    
    def process(self, input_data: Dict[str, Any]) -> Dict[str, Any]:
        """
        Procesa toda la informaci√≥n recopilada y genera un resumen estructurado
        
        Args:
            input_data: Datos de entrada (opcional)
            
        Returns:
            Resumen estructurado de la informaci√≥n recopilada
        """
        conversation_history = self._format_conversation_history()
        
        # Prompt para analizar toda la conversaci√≥n
        summary_prompt = ChatPromptTemplate.from_messages([
            ("system", """Eres un analista experto en comprender necesidades de usuarios.
            Analiza la siguiente conversaci√≥n y extrae informaci√≥n estructurada sobre:
            
            1. **Categor√≠a de producto**: Tipo de producto que busca
            2. **Presupuesto**: Rango de precio mencionado o impl√≠cito
            3. **Caracter√≠sticas prioritarias**: Qu√© caracter√≠sticas son m√°s importantes
            4. **Uso previsto**: Para qu√© necesita el producto
            5. **Preferencias espec√≠ficas**: Marcas, especificaciones t√©cnicas, etc.
            6. **Restricciones**: Limitaciones mencionadas
            7. **Informaci√≥n adicional**: Cualquier otro dato relevante
            
            Formato tu respuesta de manera clara y estructurada.
            Si alguna informaci√≥n no fue proporcionada, ind√≠calo."""),
            ("user", "Conversaci√≥n:\n\n{conversation}\n\nAnaliza y estructura esta informaci√≥n:")
        ])
        
        try:
            chain = summary_prompt | self.llm
            result = self._invoke_with_rate_limit(chain, {
                "conversation": conversation_history
            })
            
            summary = result.content
            
            # Obtener informaci√≥n extra√≠da
            extracted_info_dict = self.get_extracted_info()
            
            # Guardar en memoria
            self.update_memory("conversation_history", conversation_history)
            self.update_memory("analysis", summary)
            self.update_memory("questions_asked", self.conversation_context.questions_asked)
            self.update_memory("user_answers", self.conversation_context.user_answers)
            self.update_memory("extracted_info", extracted_info_dict)
            
            return {
                "agent": self.name,
                "status": "completed",
                "questions_asked": len(self.conversation_context.questions_asked),
                "conversation_history": conversation_history,
                "structured_analysis": summary,
                "extracted_information": extracted_info_dict,
                "information_score": self._calculate_information_score(),
                "topics_covered": self.conversation_context.topics_covered
            }
            
        except Exception as e:
            return {
                "agent": self.name,
                "status": "error",
                "error": str(e),
                "conversation_history": conversation_history
            }
    
    def reset(self):
        """Reinicia el agente para una nueva sesi√≥n"""
        self.conversation_context = ConversationContext()
        self.clear_memory()
    
    def get_progress(self) -> str:
        """
        Obtiene el progreso actual de las preguntas
        
        Returns:
            String con el progreso (ej: "3/5")
        """
        return f"{self.conversation_context.current_question_number}/{self.MAX_QUESTIONS}"
    
    def get_summary(self) -> str:
        """
        Obtiene un resumen enriquecido de la informaci√≥n recopilada hasta ahora
        
        Returns:
            Resumen detallado de la informaci√≥n
        """
        if not self.conversation_context.user_answers:
            return "No se ha recopilado informaci√≥n a√∫n."
        
        score = self._calculate_information_score()
        info_summary = self._format_extracted_info()
        
        return f"""
üìä RESUMEN DE INFORMACI√ìN RECOPILADA

üéØ Score de completitud: {score:.0f}%
{'üü¢' if score >= 70 else 'üü°' if score >= 50 else 'üî¥'} {'Excelente' if score >= 70 else 'Buena' if score >= 50 else 'Necesita m√°s informaci√≥n'}

{info_summary}

üìù Progreso:
- Preguntas realizadas: {len(self.conversation_context.questions_asked)}/{self.MAX_QUESTIONS}
- Respuestas obtenidas: {len(self.conversation_context.user_answers)}
- Temas cubiertos: {', '.join(self.conversation_context.topics_covered) if self.conversation_context.topics_covered else 'Ninguno espec√≠fico'}
"""
    
    def get_extracted_info(self) -> Dict[str, Any]:
        """
        Obtiene la informaci√≥n extra√≠da en formato de diccionario
        
        Returns:
            Diccionario con la informaci√≥n extra√≠da
        """
        info = self.conversation_context.extracted_info
        return {
            "categoria_producto": info.categoria_producto,
            "presupuesto_min": info.presupuesto_min,
            "presupuesto_max": info.presupuesto_max,
            "sin_limite_presupuesto": info.sin_limite_presupuesto,
            "uso_principal": info.uso_principal,
            "caracteristicas_clave": info.caracteristicas_clave,
            "preferencias_marca": info.preferencias_marca,
            "restricciones": info.restricciones,
            "nivel_urgencia": info.nivel_urgencia,
            "contexto_adicional": info.contexto_adicional,
            "information_score": self._calculate_information_score()
        }

