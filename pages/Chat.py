"""
Chat con Agente de IA - Sistema AURA
Basado en la guÃ­a oficial de Streamlit v2
"""

import streamlit as st
import time
from datetime import datetime
import os

# Importar componentes del sistema AURA
from src.orchestator import MultiAgentOrchestrator
from src.rag.vector_store import VectorStore
from src.rag.document_loader import DocumentLoader
from src.config import config

# ========================================
# INICIALIZACIÃ“N DEL SISTEMA
# ========================================
@st.cache_resource
def initialize_system():
    """
    Inicializa el sistema AURA cargando el VectorStore existente
    Se ejecuta solo una vez gracias a @st.cache_resource
    
    Returns:
        VectorStore si existe y se carga correctamente, None si no existe
    """
    try:
        # Validar configuraciÃ³n
        config.validate()
        config.setup_langsmith()
        
        # Verificar si existe el VectorStore procesado
        if not os.path.exists(config.CHROMA_DIR):
            return None
        
        # Verificar que el directorio no estÃ© vacÃ­o
        if not any(os.scandir(config.CHROMA_DIR)):
            return None
        
        # Cargar VectorStore existente
        print("ğŸš€ Cargando VectorStore existente...")
        vector_store = VectorStore()
        vector_store.load_vectorstore()
        print("âœ“ VectorStore cargado correctamente")
        
        return vector_store
        
    except Exception as e:
        print(f"âŒ Error cargando VectorStore: {str(e)}")
        return None


# ========================================
# GENERADOR DE RESPUESTAS CON STREAMING
# ========================================
def response_generator(response_text: str):
    """
    Genera respuestas con efecto de streaming preservando el formato
    
    Args:
        response_text: Texto de respuesta del agente
    """
    # Dividir el texto en lÃ­neas para preservar los saltos de lÃ­nea
    lines = response_text.split('\n')
    
    for i, line in enumerate(lines):
        # Procesar cada palabra de la lÃ­nea
        words = line.split()
        for j, word in enumerate(words):
            yield word + " "
            time.sleep(0.02)
        
        # Agregar salto de lÃ­nea al final de cada lÃ­nea (excepto la Ãºltima)
        if i < len(lines) - 1:
            yield "\n"

# ========================================
# CONFIGURACIÃ“N DE LA PÃGINA
# ========================================
st.set_page_config(
    page_title="Chat AURA",
    page_icon="ğŸ¤–",
    layout="centered"
)

# ========================================
# INICIALIZAR SISTEMA Y SESSION STATE
# ========================================
# Inicializar VectorStore (solo una vez)
vector_store = initialize_system()

# Verificar que el VectorStore existe
if vector_store is None:
    st.error("âš ï¸ **El sistema RAG no ha sido inicializado**")
    
    st.markdown("""
    ### ğŸ”§ ConfiguraciÃ³n Requerida
    
    Antes de poder usar el chat, necesitas preparar el sistema siguiendo estos pasos:
    
    #### ğŸ“‹ Pasos para inicializar el sistema:
    
    1. **Ve a la pÃ¡gina de ConfiguraciÃ³n** (en la barra lateral izquierda)
    
    2. **Configura las variables de entorno:**
       - Ve a la pestaÃ±a "ğŸ” Variables de Entorno"
       - Ingresa tu `GOOGLE_API_KEY`
       - Configura los parÃ¡metros del modelo
       - Guarda la configuraciÃ³n
    
    3. **Sube tus archivos de productos:**
       - Ve a la pestaÃ±a "ğŸ“ GestiÃ³n de Archivos RAG"
       - Sube archivos con informaciÃ³n de productos (Excel, CSV, JSON, PDF, etc.)
       - Los archivos deben contener la informaciÃ³n que AURA usarÃ¡ para hacer recomendaciones
    
    4. **Procesa los documentos:**
       - Ve a la pestaÃ±a "ğŸ”® InicializaciÃ³n RAG"
       - Haz clic en "ğŸš€ Procesar Documentos"
       - Espera a que el sistema procese los archivos y cree el VectorStore
       - Este proceso puede tardar 2-10 minutos dependiendo de la cantidad de datos
    
    5. **Â¡Listo!** Vuelve a esta pÃ¡gina y podrÃ¡s comenzar a chatear con AURA
    
    ---
    
    ### ğŸ“Š Estado del Sistema:
    """)
    
    col1, col2, col3 = st.columns(3)
    
    with col1:
        # Verificar .env
        env_exists = os.path.exists(".env")
        if env_exists:
            st.success("âœ… Archivo .env existe")
        else:
            st.error("âŒ Falta archivo .env")
    
    with col2:
        # Verificar archivos en uploads
        try:
            if os.path.exists("data/uploads"):
                files = list(os.scandir("data/uploads"))
                num_files = len([f for f in files if f.is_file()])
                if num_files > 0:
                    st.success(f"âœ… {num_files} archivo(s) en uploads")
                else:
                    st.error("âŒ No hay archivos en uploads")
            else:
                st.error("âŒ No hay archivos en uploads")
        except:
            st.error("âŒ No hay archivos en uploads")
    
    with col3:
        # Verificar VectorStore
        try:
            if os.path.exists(config.CHROMA_DIR):
                files = list(os.scandir(config.CHROMA_DIR))
                if len(files) > 0:
                    st.success("âœ… VectorStore procesado")
                else:
                    st.error("âŒ VectorStore no procesado")
            else:
                st.error("âŒ VectorStore no procesado")
        except:
            st.error("âŒ VectorStore no procesado")
    
    st.markdown("---")
    
    # BotÃ³n para ir a configuraciÃ³n
    st.info("ğŸ‘‰ **Haz clic en 'ConfiguraciÃ³n' en la barra lateral para comenzar**")
    
    st.stop()

# Inicializar orquestador en session_state
if "orchestrator" not in st.session_state:
    st.session_state.orchestrator = MultiAgentOrchestrator(vector_store)

if "messages" not in st.session_state:
    st.session_state.messages = []

if "conversations" not in st.session_state:
    st.session_state.conversations = []

if "current_conversation_id" not in st.session_state:
    st.session_state.current_conversation_id = None

if "session_started" not in st.session_state:
    st.session_state.session_started = False

# ========================================
# SIDEBAR - GESTIÃ“N DE CONVERSACIONES
# ========================================
with st.sidebar:
    st.header("ğŸ’¬ Conversaciones")

    # BotÃ³n para nueva conversaciÃ³n
    if st.button("â• Nueva ConversaciÃ³n", use_container_width=True, type="primary"):
        # Guardar conversaciÃ³n actual si existe
        if st.session_state.messages:
            conversation = {
                "id": datetime.now().strftime("%Y%m%d_%H%M%S"),
                "title": st.session_state.messages[0]["content"][:30] + "..." if st.session_state.messages else "Nueva conversaciÃ³n",
                "timestamp": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
                "messages": st.session_state.messages.copy()
            }
            st.session_state.conversations.append(conversation)

        # Iniciar nueva conversaciÃ³n
        st.session_state.messages = []
        st.session_state.current_conversation_id = None
        st.session_state.session_started = False
        st.session_state.orchestrator.reset()
        st.rerun()

    st.divider()

    # Mostrar conversaciones antiguas
    if st.session_state.conversations:
        st.subheader("ğŸ“š Historial")

        for idx, conv in enumerate(reversed(st.session_state.conversations)):
            col1, col2 = st.columns([4, 1])

            with col1:
                # BotÃ³n para cargar conversaciÃ³n
                if st.button(
                    f"ğŸ’¬ {conv['title'][:25]}...",
                    key=f"conv_{idx}",
                    use_container_width=True
                ):
                    st.session_state.messages = conv["messages"].copy()
                    st.session_state.current_conversation_id = conv["id"]
                    st.rerun()

            with col2:
                # BotÃ³n para eliminar conversaciÃ³n
                if st.button("ğŸ—‘ï¸", key=f"del_{idx}"):
                    st.session_state.conversations.remove(conv)
                    st.rerun()

            # Mostrar timestamp
            st.caption(f"ğŸ• {conv['timestamp']}")
            st.divider()
    else:
        st.info("No hay conversaciones guardadas")

    # EstadÃ­sticas
    st.divider()
    st.subheader("ğŸ“Š EstadÃ­sticas")
    st.metric("Conversaciones guardadas", len(st.session_state.conversations))
    st.metric("Mensajes en esta conversaciÃ³n", len(st.session_state.messages))

# ========================================
# TÃTULO
# ========================================
st.title("ğŸ¤– Chat con Agente AURA")

# Mostrar estado del sistema
status_col1, status_col2 = st.columns([3, 1])
with status_col1:
    if st.session_state.session_started:
        st.caption(f"ğŸŸ¢ SesiÃ³n activa | Estado: {st.session_state.orchestrator.get_state()}")
    else:
        st.caption("ğŸŸ¡ Listo para comenzar")
with status_col2:
    if st.button("ğŸ”„ Reiniciar", help="Reiniciar el flujo de recomendaciones"):
        st.session_state.orchestrator.reset()
        st.session_state.session_started = False
        st.session_state.messages = []
        st.rerun()

st.divider()

# ========================================
# INICIAR SESIÃ“N SI ES LA PRIMERA VEZ
# ========================================
if not st.session_state.session_started and not st.session_state.messages:
    with st.chat_message("assistant"):
        initial_message = st.session_state.orchestrator.start_session()
        st.markdown(initial_message)
    
    st.session_state.messages.append({"role": "assistant", "content": initial_message})
    st.session_state.session_started = True

# ========================================
# MOSTRAR MENSAJES DEL HISTORIAL
# ========================================
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

# ========================================
# ACEPTAR INPUT DEL USUARIO
# ========================================
if prompt := st.chat_input("Â¿En quÃ© puedo ayudarte?"):
    # Agregar mensaje del usuario al historial
    st.session_state.messages.append({"role": "user", "content": prompt})

    # Mostrar mensaje del usuario en el contenedor
    with st.chat_message("user"):
        st.markdown(prompt)

    # Procesar con el orquestador
    with st.chat_message("assistant"):
        with st.spinner("ğŸ¤” Pensando..."):
            # Procesar la entrada del usuario
            result = st.session_state.orchestrator.process_user_input(prompt)
            
            # Obtener la respuesta
            response_text = result.get("message", "Lo siento, hubo un error.")
            
            # Mostrar respuesta con streaming
            response = st.write_stream(response_generator(response_text))
            
            # Mostrar informaciÃ³n adicional si estÃ¡ disponible
            if result.get("status") == "completed":
                # Mostrar productos encontrados
                if "products_found" in result:
                    st.info(f"ğŸ“¦ Se encontraron {result['products_found']} productos relevantes")
                
                # OpciÃ³n para ver anÃ¡lisis detallado
                with st.expander("ğŸ“Š Ver anÃ¡lisis detallado"):
                    if st.session_state.orchestrator.workflow_data.get('user_analysis'):
                        st.write("**AnÃ¡lisis de tus necesidades:**")
                        st.write(st.session_state.orchestrator.workflow_data['user_analysis'])
                    
                    if st.session_state.orchestrator.workflow_data.get('criteria'):
                        st.write("\n**Criterios de bÃºsqueda:**")
                        st.write(st.session_state.orchestrator.workflow_data['criteria'])
            
            elif result.get("status") == "collecting":
                # Mostrar progreso
                if "progress" in result:
                    st.caption(f"ğŸ“‹ Progreso: {result['progress']}")
            
            elif result.get("status") == "error":
                st.error("âŒ OcurriÃ³ un error. Por favor, intenta de nuevo.")

    # Agregar respuesta del asistente al historial
    st.session_state.messages.append({"role": "assistant", "content": response})
